{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This assignment is to be completed in R and returned as a clean Jupyter notebook cleared of its output. This is important otherwise Turnitin will reject the submission.\n",
    "\n",
    "The answers require text and/or code and each one is assigned an individual cell with the message \"*(Write your text here)*\" or \"*(Write your code here)*\". **You only need to write on those cells**. \n",
    "\n",
    "\n",
    "<span style='color:Blue'> Code answers  </span>: Each part of each problem requires you to write  code that returns the output prompted when running the cell.\n",
    "\n",
    "<span style='color:Blue'> Text answers  </span>: When required by the problem, you need to write enough text interpreting the output of the code. \n",
    "\n",
    "There are three problems to be tackled:\n",
    "1. Plotting data and basic hypothesis testing [40%]\n",
    "2. Multiple regression [40%]\n",
    "3. Hierarchical modelling [20%]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "- The kernel for this Jupyter notebook is R, version 4.1.0, with the following packages: MuMIn, rstanarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the following libraries for your answers\n",
    "library(MuMIn)\n",
    "library(rstanarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 1: Plotting data\n",
    "\n",
    "You are given a dataset of ten years of Bioinformatics MSc students at Imperial College London and their end-of-year marks. Various data about the students have been collected, including: age (years), height (metres), eye colour (categorical), grey-cell brain density index (a unitless index of brain structure), the year of their graduation, their enthusiasm for the Bioinformatics course (measured in 'joys'), and their final degree percentage. All ethical approval required for imaginary data have been obtained. The data is provided in the file `q1-2021.csv`.\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Load the dataset `q1-2021.csv`.\n",
    "How many students were surveyed? How many different eye-colours have been recorded?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#part_1\n",
    "#importing q1-2021.csv\n",
    "q1_df <- read.csv(\"q1-2021.csv\")\n",
    "#first row is empty so we will exclude it from the rest of our analysis\n",
    "q1_df <- q1_df[,-1]\n",
    "#eye colour is categorical so we will save it as a factor/categorical variable\n",
    "q1_df$eyecolour <- as.factor(q1_df$eyecolour)\n",
    "\n",
    "#q1 how many students were surveyed?\n",
    "part1_a <- nrow(q1_df)\n",
    "#q2 how many different eye colours have been recorded?\n",
    "part1_b <- length(levels(q1_df$eyecolour))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> Text Answer  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#q1 how many students were surveyed?\n",
    "\n",
    "$200.$\n",
    "\n",
    "#q2 how many different eye colours have been recorded?\n",
    "\n",
    "$\\text{3 different eye colours. blue, green and green}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Produce a plot to show the relationship between (1) degree mark and age and (2) degree mark and year of graduation. Do not simply use the default plotting options; alter the appearance of each plot in some way from the default (e.g., add a title, change the plotting symbol or colour)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(scales)\n",
    "#we will plot degree marks on the y axis as it is a response variable in both cases.\n",
    "plot_1 <- ggplot(data=q1_df,aes(y=mark,x=age))+\n",
    "  geom_point(shape=23)+\n",
    "  labs(title=\"Imperial College MSc Bioinformatics and Theoretical \\nSystems Biology\",y=\"Degree mark (%)\",x=\"Age (years)\")+\n",
    "  theme_gray()\n",
    "plot_1\n",
    "\n",
    "\n",
    "plot_2  <- ggplot(data=q1_df,aes(y=mark,x=cohort))+\n",
    "  geom_point(shape=1)+\n",
    "  labs(title=\"Imperial College MSc Bioinformatics and Theoretical \\nSystems Biology\",y=\"Degree mark (%)\",x=\"Year of Graduation\")+\n",
    "  theme_gray()+\n",
    "  scale_x_continuous(breaks=pretty_breaks())\n",
    "plot_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "Standardise the grey-cell index by age, dividing the index by age. Plot the relationship between mark and this standardised index and report whether there is a statistically significant relationship between the two indices. Report what in your code gives support for your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "q1_df$brain_standard <- q1_df$grey.density/q1_df$age\n",
    "\n",
    "plot_3 <- ggplot(data=q1_df,aes(x=brain_standard,y=mark))+\n",
    "  geom_point(shape=1)+\n",
    "  labs(title=\"Imperial College MSc Bioinformatics and Theoretical \\nSystems Biology\",x=expression(Standardised~Grey~Cell~Brain~Density~index~(year^{-1})),y=\"Degree Mark (%)\")\n",
    "plot_3\n",
    "#will use a correlation test to see if degree mark is related to the standardised index of grey.density\n",
    "#pearson correlation relies upon normally distributed variables.\n",
    "hist(q1_df$mark) #roughly normal\n",
    "hist(log(q1_df$brain_standard)) #highly skewed to the right\n",
    "\n",
    "#because the standardised index is right skewed we will have to use a non parametric correlation test. We will apply both Spearman's rho and Kendall's tau.\n",
    "cor.test(x=q1_df$brain_standard,y=q1_df$mark,method=\"kendall\")\n",
    "cor.test(x=q1_df$brain_standard,y=q1_df$mark,method=\"spearman\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Text Answer  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "No significant correlation (Spearman's $\\rho=-0.053,p=0.45,n=200$) and dependence (Kendall's $\\tau =-0.038,p=0.42,n=200$) is found between the standardised index for grey cell density ($y^{-1}$)  and degree mark (%). Results obtained from cor.test() using the \"spearman\" and \"kendall\" methods in R v4.2.2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "Plot the relationship between mark and enthusiasm for the course, and report whether there is a statistically significant relationship between the two. Make sure to add a trend-line to your figure. Report what in your code gives support for your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_4 <- ggplot(data=q1_df,aes(x=enthusiasm,y=mark))+\n",
    "  geom_point()+\n",
    "  geom_smooth(method=\"lm\",se=FALSE)+\n",
    "  labs(title=\"Imperial College MSc Bioinformatics and Theoretical \\nSystems Biology\",\n",
    "       x=\"Enthusiasm (Joys)\",\n",
    "       y=\"Degree Mark (%)\")\n",
    "  \n",
    "plot_4\n",
    "hist(q1_df$mark) #visual inspection suggestions normal distribution\n",
    "hist(q1_df$enthusiasm) #not normally distributed\n",
    "#enthusiasm does not not meed the conditions to apply a pearson correlation\n",
    "cor.test(x=q1_df$mark,y=q1_df$mark,method=\"spearman\")\n",
    "cor.test(x=q1_df$enthusiasm,y=q1_df$mark,method=\"kendall\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Text Answer  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "A significant correlation (Spearman's $\\rho=1,p<0.001,n=200$) and dependence (Kendall's $\\tau =0.371,p<0.001,n=200$) is found between Enthusiasm (joys) and degree mark (%). Results obtained from cor.test() using the \"spearman\" and \"kendall\" methods in R v4.2.2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 2: Multiple regression\n",
    "\n",
    "You have been given a dataset on the effective reproduction number ('Rt') of SARS-CoV-2 early in the pandemic across regions of the US in June 2020. This number can go as low as 0 in regions where there is essentially no transmission, and numbers greater than 1 indicate a growing population of SARS-CoV-2. The regions (their names and locations are unimportant) have associated data: temperature (in degrees Centigrade), humidity (percentage saturation of the air with water), population density (mean number of people per square kilometer), and non-pharmaceutical intervention strength (a dimensionless, normalised index of lockdown strength and mask compliance). While these data are simulated, they are based on a real-world exercise that researchers at Imperial carried out early in the pandemic (see Smith et al. 2021 PNAS 118 (25) e2019284118).\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Load the data into R from the file `q2-2021.csv`. Fit an additive model with Rt as the response variable and all other variables as explanatory variables. Summarise briefly what this model shows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Part 1\n",
    "\n",
    "###\n",
    "\n",
    "q2_df <- read.csv(\"q2-2021.csv\")\n",
    "#first collumn is unneccesary\n",
    "q2_df <- q2_df[,-1]\n",
    "\n",
    "additive_model <- lm(data=q2_df,formula=Rt~temp+humid+pop.dens+exposure)\n",
    "summary(additive_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Text Answer  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The additive model explains significantly more variation in $R_t$ than a null model with $R_t \\sim  \\mu$. ($F_{4,495}=312.3,\\, p<0.001,\\, R^2=0.7162,\\, R^2_{adj}=0.7139$). All parameters significantly predicted $R_{t}$.\n",
    "\n",
    "\n",
    "| Parameter          | Estimate  | Std.error | t value   | Pr(>\\|t\\|) |\n",
    "|--------------------|-----------|-----------|-----------|------------|\n",
    "| Intercept          | 3.22E+00  | 5.41E-01  | 5.95E+00  | 4.97E-09   |\n",
    "| Temperature        | -9.49E-02 | 2.69E-02  | -3.53E+00 | 4.53E-04   |\n",
    "| Humidity           | 1.16E-02  | 9.19E-04  | 1.26E+01  | < 2e-16    |\n",
    "| Population density | 8.82E-06  | 1.24E-06  | 7.09E+00  | 4.66E-12   |\n",
    "| NPI-strength       | -8.44E-01 | 2.68E-02  | -3.15E+01 | < 2e-16    |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "There are good reasons from theory to suppose that the impact of population density and non-pharmaceutical interventions are non-linear. Apply a log10 transformation to the population density data and a logistic transformation (function definition given below so that it can be used analogously to the `log10` function in R) to your variables and use ANOVA to test for an improvement in model fit after these transformations. Note that, because there will be no difference in the number of parameters in your model, you will not be able to generate a probability (p-value) for this test. Thus you will need to interpret the F-statistic itself and use your statistical judgement. Briefly provide your reasoning in your answer.\n",
    "\n",
    "`logistic <- function(x) 1/(1+exp(-x))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Part 2\n",
    "logistic <- function(x) 1/(1+exp(-x))\n",
    "q2_df$log_Pop_density <- log10(q2_df$pop.dens)\n",
    "q2_df$logit_npi <- logistic(q2_df$exposure)\n",
    "transf_additive_model <- lm(data=q2_df,formula=Rt~temp+humid+log_Pop_density+logit_npi)\n",
    "summary(transf_additive_model)\n",
    "#line below will not generate an F statistic\n",
    "anova(transf_additive_model,additive_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Text Answer  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "(Write your text here)\n",
    "Because the purely additive model and the transformed additive model have the same number of parameters ($5$). An F test to see if the transformed additive model explains more variation than the purely additive model cannot be performed.\n",
    "\n",
    "$$\n",
    "F=\\frac{(SSM_{a}-SSM_{n}\\times (n-k_{a}-1))}{SSE \\times k_{a}-k_{n}}\n",
    "$$\n",
    "\n",
    "Because $k_{a}=k_{b}=5.$ $k_{a}-k_{n}=0$ and no F statistic can be calculated. Instead we will calculate the $F$ statistic of the transformed model against the null model $R_{t} \\sim \\mu$\n",
    "\n",
    "$$F_{4,495}=407.6,\\, p<0.001, \\, R^{2}=0.7652$$\n",
    "\n",
    "We reccomend accepting the transformed model as the ratio of variation explained by the model $SSM$ to $SSE$ is $1.3\\times$ greater in the transformed model. $\\frac{407.6}{312.3}=1.31$. In more intuitive terms, a greater amount of variation is explained by the model while estimating the same amount of parameters.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part 3\n",
    "\n",
    "Identify the most important drivers of transmission (Rt) in this dataset and quantify their relative importances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#part 3\n",
    "#standardising explanatory variables\n",
    "q2_df_scaled <- scale(q2_df[,-5]) #NB not standardising the response variable Rt.\n",
    "q2_df_scaled <- as.data.frame(q2_df_scaled) #scale produces a matrix, changing to data frame\n",
    "q2_df_scaled$Rt <- q2_df$Rt\n",
    "#building transformed_additive_model\n",
    "transf_additive_model_scaled <- lm(data=q2_df_scaled,formula=Rt~temp+humid+log_Pop_density+logit_npi)\n",
    "#Reference: Groempig et al 2007 DOI:https://www.jstatsoft.org/article/view/v017i01\n",
    "#Within this paper reference is made to two ways of quantifying importance of a variable in a linear model. The dispersion importance relating to the explained sum of squares/ R^2 as can be done in the library relaimpo and the level importance relating to the effect size of a variable on the mean of the response variable.\n",
    "# we will be calculating relative importance using standardised variables and the standard effect sizes as the question asks for the important *drivers* of Rt as opposed to the *most explanatory* variables.\n",
    "summary(transf_additive_model_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Text Answer  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "The drivers of $R_{t}$ in descending order of importance is the $\\text{logit}(\\text{NPI})$  which has a  $0\n",
    ".85/0.33=2.93 \\times$ greater effect than $\\text{humidity}$ followed by $\\log_{10}(\\text{Population Density})$ which is $0.29/0.33=0.879 \\times$ weaker than $\\text{humidity}$ followed by $\\text{temperature}$ which is $0.09/0.29=0.310 \\times $ weaker than $\\log_{10}(\\text{Population Density})$. \n",
    "\n",
    "|          Parameter         | Effect Size |\n",
    "|:--------------------------:|:-----------:|\n",
    "|          Intercept         |     2.01    |\n",
    "|         Temperature        |    -0.09    |\n",
    "|          Humidity          |     0.33    |\n",
    "|  log10(Population density) |     0.29    |\n",
    "|     logit(NPI-strength)    |    -0.85    |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "\n",
    "There are strong theoretical grounds to suppose that the impact of non-pharameutical interventions mediate the impact of all other variables in this analysis. Statistically test for evidence that non-pharmaceutical interventions interact with all other variables in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: library not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: library not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ x:\\OneDrive - Imperial College London\\school\\MSc\\Maths_and_computing\\assignment_MscBS_2022\\assignment_MscBS_2022\\assignment_stats\\assignmentSTATS_MSc2021.ipynb:1"
     ]
    }
   ],
   "source": [
    "library(MuMIn)\n",
    "# Load package (named for Moomin cartoons)\n",
    "\n",
    "#now building top model using transformed variables\n",
    "top_standard_model <- lm(data=q2_df_scaled,formula=Rt~(temp+humid+log_Pop_density+logit_npi*temp+logit_npi*humid+logit_npi*log_Pop_density),na.action = na.pass)\n",
    "# 'dredging' through all the subsets\n",
    "models <- dredge(top_standard_model)\n",
    "# Subset our models to contain only those within 4 AIC units of the best model\n",
    "# - this is the standard number, but there's no reason to use one over another really\n",
    "# - then summarize across the average of these models\n",
    "summary(model.avg(models, subset=delta<4, fit=TRUE))\n",
    "# Get the AIC importance values (the 'summed weights')\n",
    "sw(model.avg(models, subset=delta<4, fit=TRUE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Text Answer  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Out of all subsets of interactions between $\\text{logit}(\\text{NPI})$ and the other variables within $4 \\text{AIC}$ units of the best model, 2 models were obtained. The best performing model includes all variables and interactions and the second model differs in that it excludes an interaction between $\\text{logit}(\\text{NPI})$ and $\\text{temperature}$. The models perform highly similarly with very similar AICs.\n",
    "\n",
    "|  Component model  | log likelihood |  AICc  | delta AIC | weight |\n",
    "|:-----------------:|:--------------:|:------:|:---------:|:------:|\n",
    "|     All terms     |     -356.92    | 732.22 |     0     |  0.55  |\n",
    "|  -logit(NPI):temp |     -358.18    | 732.65 |    0.44   |  0.45  |\n",
    "\n",
    "The effect size of the interaction terms between $\\text{logit}(\\text{NPI})$ are of comparable effect size to $\\text{temperature}$ except for the interaction between $\\text{temperature}$ and $\\text{logit}(\\text{NPI})$ and $\\text{temperature}$ which is much smaller due to the unconditional averaging. Even in the model where it is present the effect size is notably small $\\text{Estimate}= 0.036$.\n",
    "\n",
    "|     Model   Averaged Coefficients    | Estimate | z value | Pr(>\\|z\\|) |\n",
    "|:------------------------------------:|:--------:|:-------:|:----------:|\n",
    "|               Intercept              |  2.0125  |  90.051 |   <2E-16   |\n",
    "|               humidity               |  0.32227 |  14.305 |   <2E-16   |\n",
    "|        log(Population density)       |  0.29171 |  12.985 |   <2E-16   |\n",
    "|              logit(NPI)              | -0.85415 |  38.148 |   <2E-16   |\n",
    "|              temperature             | -0.10147 |  4.524  |  6.10E-06  |\n",
    "|          humidity:logit(NPI)         | -0.10836 |  4.952  |  7.00E-07  |\n",
    "| log(Population   density):logit(NPI) |  -0.1459 |  6.579  |   <2E-16   |\n",
    "|        logit(NPI):temperature        |  0.01996 |  0.807  |    0.419   |\n",
    "\n",
    "Finally looking at the summed weights it seems clear that $\\text{logit}(\\text{NPI})$:$\\text{temperature}$ does not have as much support for its inclusion in our final model.\n",
    "This is not to claim that the interaction is not important or informative as it does lower the AIC of the model containing it. However, given its low effect size and little loss in AIC we reccomend picking the simpler model.\n",
    "\n",
    "|                                      | Sum of weights | # of models containing parameter |\n",
    "|:------------------------------------:|:--------------:|:--------------------------------:|\n",
    "|               humidity               |      1.00      |                 2                |\n",
    "|        log(Population density)       |      1.00      |                 2                |\n",
    "|              logit(NPI)              |      1.00      |                 2                |\n",
    "|              temperature             |      1.00      |                 2                |\n",
    "|          humidity:logit(NPI)         |      1.00      |                 2                |\n",
    "| log(Population   density):logit(NPI) |      1.00      |                 2                |\n",
    "|        logit(NPI):temperature        |      0.55      |                 2                |\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Hierarchical modelling\n",
    "\n",
    "You are given a dataset (`q3-2021.csv`) on scream intensity (decibels) and statistics exam performance (%), generated by a well-known statistical consultancy company (https://xkcd.com/2533/). Fit an appropriate model to these data to test whether scream intensity is associated with exam performance. Make sure to clearly explain why you chose your particular statistical formulation, and to reference whether you find, or do not find, support for the hypothesis with reference to your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Code Answer  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3_df <- read.csv(\"q3-2021.csv\")\n",
    "#first collumn unneccesary\n",
    "q3_df <- q3_df[,-1]\n",
    "\n",
    "\n",
    "library(ggplot2)\n",
    "ggplot(data=q3_df,aes(x=scream,y=grade,col=student))+\n",
    "  geom_point()+geom_smooth(method=\"lm\")+\n",
    "  labs(title=\"STATS EXAM GRADE\",x=\"SCREAM LOUDNESS (DECIBELS)\",y=\"GRADE (%)\")\n",
    "\n",
    "library(rstanarm)\n",
    "model <- stan_glmer(grade ~ scream + (1|student),data=q3_df)\n",
    "\n",
    "\n",
    "# More comprehensive and useful coefficients\n",
    "summary(model, probs=c(.025, .5, .975))\n",
    "# \"Caterpillar\" coefficient plots\n",
    "plot(model)\n",
    "# MCMC diagnostics (see note in text)\n",
    "plot(model, \"trace\")\n",
    "\n",
    "# area plots\n",
    "# all of the parameters\n",
    "# scale of parameters is so varied\n",
    "# that it's hard to see the details\n",
    "library(bayesplot)\n",
    "sims <- as.matrix(model)\n",
    "plot_title <- ggtitle(\"Posterior distributions\",\n",
    "                      \"with medians and 95% intervals\")\n",
    "mcmc_areas(sims, prob = 0.9) + plot_title\n",
    "\n",
    "# area plot for scream parameter\n",
    "mcmc_areas(sims,\n",
    "           pars = c(\"scream\"),\n",
    "           prob = 0.9) + plot_title\n",
    "\n",
    "posterior_interval(model,pars=\"scream\",prob=0.53) #23.5 % of distribution below 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style='color:Blue'> Text Answer  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "It is clear from the plots of Grade against Scream Loudness that the student screaming highly influences both the scream and the grade achieved. A linear model would be \"swamped\" by the explanatory power of the student and would not reliably test the relationship between scream and grade. We suggest a heirarchical model where the student varies the intercept of the grade parameter. We chose to implement this heirarchical model in a Bayesian framework as this allows us to visualise a posterior distribution for the scream parameter. Addtionally, mixed effects models do not allow for testing the significance of any fixed effect or calculating the $r^2$.\n",
    "\n",
    "We ran a MCMC Bayesian heirarchical model using rstanarm running a total of 4 chains of 2000 iterations sampling every $200$ iterations. The models were checked graphically for convergence and $\\hat r$ were all equal to 1. We applied normally distributed priors with a $\\mu$ of $0$ so as to be uninformative.\n",
    "\n",
    "Parameter Estimates and their posterior distributions are summarised in the penultimate plot. The posterior distribution for the scream parameter is found in the final plot and is found to lie with 95% probability within the left skewed interval $[-0.5,1.4]$ with a mean of $0.3$. We conclude that there is insufficient evidence for screams to be associated with statistics grades even when controlling for variation between students because the 95% posterior interval contains 0 and indeed  $\\sim25\\%$ of the distribution (last line) is $<0$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba16fd9f84400e5dd1811ddc1f1c1ab06f6c8d23b67e3c4acee5f2ccc73d4a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
